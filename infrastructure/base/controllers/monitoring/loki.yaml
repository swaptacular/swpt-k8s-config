apiVersion: helm.toolkit.fluxcd.io/v2
kind: HelmRelease
metadata:
  name: loki
  namespace: monitoring
spec:
  interval: 10m
  chart:
    spec:
      chart: charts/loki-6.30.1.tgz
      sourceRef:
        kind: GitRepository
        name: flux-system
        namespace: flux-system

  targetNamespace: monitoring
  releaseName: loki
  values:
    global:
      image:
        # Overrides the container registry globally for all images.
        registry: null
      extraArgs:
        - "-config.expand-env=true"
      extraEnvFrom:
        - secretRef:
            name: loki-object-store
      extraVolumes:
        - name: minio-ca-certificate
          configMap:
            name: kube-root-ca.crt
      extraVolumeMounts:
        - name: minio-ca-certificate
          mountPath: /certs/minio
      priorityClassName: critical-monitoring
    imagePullSecrets:
      - name: regcreds
    loki:
      image:
        repository: grafana/loki
        digest: null
      auth_enabled: false
      commonConfig:
        replication_factor: 1  # This is 3 by default.
      schemaConfig:
        configs:
          - from: "2024-04-01"
            store: tsdb
            object_store: s3
            schema: v13
            index:
              prefix: loki_index_
              period: 24h
      storage:
        type: s3
        s3:
          endpoint: "${AWS_ENDPOINT}"
          region: "${AWS_REGION}"
          accessKeyId: "${AWS_ACCESS_KEY_ID}"
          secretAccessKey: "${AWS_SECRET_ACCESS_KEY}"
          s3ForcePathStyle: true
          insecure: false
          http_config:
            # This specifies the trusted CA for the local MinIO S3
            # server. This should not be necessary for "proper" S3
            # providers.
            ca_file: /certs/minio/ca.crt
        bucketNames:
          chunks: loki-chunks
          ruler: loki-ruler
          admin: loki-admin
      ingester:
        chunk_encoding: snappy
        wal:
          # Maximum memory size the WAL may use during replay. After
          # hitting this, it will flush data to storage before
          # continuing. A unit suffix (KB, MB, GB) may be applied. The
          # default is 4GB. Normally, this should be about 75% of the
          # memory request for the ingester pods.
          replay_memory_ceiling: 100MB
      querier:
        # Default is 4, if you have enough memory and CPU you can increase, reduce if OOMing
        max_concurrent: 4
      compactor:
        retention_enabled: true
        delete_request_store: s3
      limits_config:
        retention_period: 30d
        max_query_lookback: 30d
    write:
      replicas: 1
      persistence:
        size: 1Gi  # Should be >= 10Gi in production
        storageClass: null
        enableStatefulSetAutoDeletePVC: false
      resources: {}  # The memory request should be >= 5Gi in production.
    read:
      replicas: 1
      resources: {}
    backend:
      replicas: 1
      persistence:
        size: 1Gi  # Should be >= 10Gi in production
        storageClass: null
        enableStatefulSetAutoDeletePVC: false
      resources: {}
    chunksCache:
      replicas: 1
      allocatedMemory: 128  # Megabytes
      priorityClassName: critical-monitoring
      persistence:
        enabled: true
        storageSize: 2Gi
        storageClass: null
      affinity:
        podAntiAffinity:
          requiredDuringSchedulingIgnoredDuringExecution:
          - labelSelector:
              matchLabels:
                app.kubernetes.io/component: memcached-chunks-cache
            topologyKey: kubernetes.io/hostname
    resultsCache:
      replicas: 1
      allocatedMemory: 64  # Megabytes
      priorityClassName: critical-monitoring
      persistence:
        enabled: true
        storageSize: 2Gi
        storageClass: null
      affinity:
        podAntiAffinity:
          requiredDuringSchedulingIgnoredDuringExecution:
          - labelSelector:
              matchLabels:
                app.kubernetes.io/component: memcached-results-cache
            topologyKey: kubernetes.io/hostname
    lokiCanary:
      enabled: true
      image:
        repository: grafana/loki-canary
        digest: null
      resources: {}
    gateway:
      replicas: 1
      image:
        repository: nginxinc/nginx-unprivileged
        digest: null
      resources: {}
    sidecar:
      image:
        # The registry must be included in the "repository" value
        # ("docker.io" for example), because the chart ignores the
        # value of "global.image.registry" for sidecars.
        repository: docker.io/kiwigrid/k8s-sidecar
        tag: 1.30.3
        sha: ""
      resources: {}
    memcachedExporter:
      resources: {}
    test:
      enabled: true
      image:
        repository: grafana/loki-helm-test
        digest: null
    kubectlImage:
      repository: bitnami/kubectl
      digest: null
    networkPolicy:
      enabled: false
