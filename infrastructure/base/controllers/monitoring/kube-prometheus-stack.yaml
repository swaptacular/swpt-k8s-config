apiVersion: helm.toolkit.fluxcd.io/v2
kind: HelmRelease
metadata:
  name: kube-prometheus-stack
  namespace: monitoring
spec:
  interval: 10m
  chart:
    spec:
      chart: charts/kube-prometheus-stack-74.0.0.tgz
      sourceRef:
        kind: GitRepository
        name: flux-system
        namespace: flux-system

  targetNamespace: monitoring
  releaseName: prometheus
  postRenderers:
    - kustomize:
        patches:
          # Giving Grafana access to all secrets (which is the chart's
          # default) does not look like a good idea. This patch gives
          # Grafana access only to configmaps.
          - target:
              group: rbac.authorization.k8s.io
              version: v1
              kind: ClusterRole
              name: prometheus-grafana-clusterrole
            patch: |
              - op: replace
                path: /rules/0/resources
                value: ["configmaps"]
  values:
    global:
      imagePullSecrets:
        - name: regcreds

      # Global image registry to use if it needs to be overridden for
      # some specific use cases (e.g local registries, custom images)
      imageRegistry: null

    alertmanager:
      config:
        global: {}
        receivers:
          - name: email
            email_configs: {}
          - name: 'null'
        route:
          receiver: email
          routes:
            - receiver: email
              matchers:
                - alertname = "Watchdog"
      alertmanagerSpec:
        image:
          repository: prometheus/alertmanager
          sha: ""
        replicas: 1
        externalUrl: https://127.0.0.1/alertmanager/  # The IP address will be automatically replaced.
        routePrefix: /alertmanager/
        volumes:
          - name: smtp-password
            secret:
              secretName: alertmanager-prometheus-kube-prometheus-alertmanager-smtp-password
        volumeMounts:
          - mountPath: /etc/secrets/smtp-password
            name: smtp-password
            subPath: password
        storage:
          volumeClaimTemplate:
            spec:
              accessModes:
              - ReadWriteOnce
              resources:
                requests:
                  storage: 1Gi
        priorityClassName: critical-monitoring
        resources:
          limits:
            cpu: 200m
            memory: 200Mi
          requests:
            cpu: 100m
            memory: 100Mi
        podAntiAffinity: "hard"
      networkPolicy:
        enabled: false
      podDisruptionBudget:
        enabled: true
        minAvailable: null
        maxUnavailable: 30%
        unhealthyPodEvictionPolicy: AlwaysAllow

    prometheusOperator:
      image:
        repository: prometheus-operator/prometheus-operator
        sha: ""
      priorityClassName: critical-operator
      resources:
        limits:
          cpu: 200m
          memory: 200Mi
        requests:
          cpu: 100m
          memory: 100Mi
      admissionWebhooks:
        patch:
          image:
            repository: ingress-nginx/kube-webhook-certgen
            sha: ""
      prometheusConfigReloader:
        image:
          repository: prometheus-operator/prometheus-config-reloader
          sha: ""
        resources:
          requests:
            cpu: 10m
            memory: 50Mi
          limits:
            cpu: 200m
            memory: 50Mi

    prometheus:
      prometheusSpec:
        image:
          repository: prometheus/prometheus
          tag: v3.4.2
          sha: ""
        replicas: 1  # must be exactly 1
        retention: 10d
        externalUrl: https://127.0.0.1/prometheus/  # The IP address will be automatically replaced.
        routePrefix: /prometheus/
        storageSpec:
          volumeClaimTemplate:
            spec:
              accessModes:
              - ReadWriteOnce
              resources:
                requests:
                  storage: 10Gi
        priorityClassName: critical-monitoring
        resources:
          limits:
            cpu: "4"
            memory: 2Gi
          requests:
            cpu: 100m
            memory: 500Mi
        podAntiAffinity: "hard"
      networkPolicy:
        enabled: false
      podDisruptionBudget:
        enabled: true
        minAvailable: null
        maxUnavailable: 50%
        unhealthyPodEvictionPolicy: AlwaysAllow

    grafana:
      enabled: true
      image:
        repository: grafana/grafana
        tag: 12.0.2
        sha: ""
      replicas: 1  # must be exactly 1
      deploymentStrategy:
        type: Recreate
      persistence:
        enabled: true
        size: 5Gi
      admin:
        existingSecret: "prometheus-grafana-admin"
        userKey: admin-user
        passwordKey: admin-password
      additionalDataSources:
        - name: Loki
          type: loki
          uid: loki
          access: proxy
          url: http://loki-gateway.monitoring
      grafana.ini:
        plugins:
          plugin_admin_enabled: false
          public_key_retrieval_disabled: true
          plugin_catalog_url: invalid
          disable_plugins: "grafana-pyroscope-app grafana-exploretraces-app"
        grafana_com:
          api_url: invalid
          url: invalid
        grafana_net:
          url: invalid
        log:
          level: warn
        analytics:
          enabled: false
          reporting_enabled: false
          check_for_updates: false
          check_for_plugin_updates: false
          feedback_links_enabled: false
        security:
          disable_gravatar: true
        snapshots:
          external_enabled: false
      plugins:
        - http://prometheus-grafana-plugins.monitoring/grafana-lokiexplore-app-1.0.20.zip;grafana-lokiexplore-app
        - http://prometheus-grafana-plugins.monitoring/grafana-metricsdrilldown-app-1.0.4.zip;grafana-metricsdrilldown-app
      sidecar:
        image:
          repository: kiwigrid/k8s-sidecar
          tag: 1.30.3
          sha: ""
        dashboards:
          resource: configmap
        datasources:
          resource: configmap
        resources:
          requests:
            cpu: 10m
            memory: 128Mi
          limits:
            cpu: 100m
            memory: 128Mi
      service:
        type: ClusterIP
      serviceMonitor:
        labels:
          release: prometheus
      priorityClassName: critical-monitoring
      resources:
        requests:
          cpu: 10m
          memory: 180Mi
        limits:
          cpu: 200m
          memory: 500Mi
      podDisruptionBudget:
        maxUnavailable: 50%
        unhealthyPodEvictionPolicy: AlwaysAllow
      initChownData:
        enabled: false
      testFramework:
        enabled: false

    kube-state-metrics:
      image:
        repository: kube-state-metrics/kube-state-metrics
        sha: ""
      replicas: 1
      affinity: |
        podAntiAffinity:
          requiredDuringSchedulingIgnoredDuringExecution:
            - labelSelector:
                matchLabels:
                  {{- include "kube-state-metrics.selectorLabels" . | indent 10 }}
              topologyKey: kubernetes.io/hostname
              matchLabelKeys:
              - pod-template-hash
      priorityClassName: critical-monitoring
      resources:
        limits:
         cpu: 100m
         memory: 64Mi
        requests:
         cpu: 10m
         memory: 32Mi
      podDisruptionBudget:
        maxUnavailable: 30%
        unhealthyPodEvictionPolicy: AlwaysAllow

    prometheus-node-exporter:
      image:
        repository: prometheus/node-exporter
        digest: ""
      priorityClassName: critical-monitoring
      resources:
        limits:
          cpu: 200m
          memory: 50Mi
        requests:
          cpu: 10m
          memory: 30Mi
