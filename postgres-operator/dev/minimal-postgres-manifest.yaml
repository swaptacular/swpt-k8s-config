apiVersion: "acid.zalan.do/v1"
kind: postgresql
metadata:
  name: test-cluster
  namespace: default
spec:
  teamId: "swpt"
  numberOfInstances: 2
  postgresql:
    version: "17"
  users:
    test_owner: []
  databases:
    test: test_owner
  patroni:
    synchronous_mode: true
  resources:
    requests:
      cpu: 10m
    limits:
      cpu: 500m
      memory: 350Mi
  volume:
    size: 1Gi
  additionalVolumes:
    - name: minio-ca-certificate
      mountPath: /certs/minio
      targetContainers: []
      volumeSource:
        configMap:
          name: kube-root-ca.crt
  env:
    - name: CLONE_AWS_ACCESS_KEY_ID
      valueFrom:
        secretKeyRef:
          name: spilo-custom-secret
          key: AWS_ACCESS_KEY_ID
    - name: CLONE_AWS_SECRET_ACCESS_KEY
      valueFrom:
        secretKeyRef:
          name: spilo-custom-secret
          key: AWS_SECRET_ACCESS_KEY
    - name: STANDBY_AWS_ACCESS_KEY_ID
      valueFrom:
        secretKeyRef:
          name: spilo-custom-secret
          key: AWS_ACCESS_KEY_ID
    - name: STANDBY_AWS_SECRET_ACCESS_KEY
      valueFrom:
        secretKeyRef:
          name: spilo-custom-secret
          key: AWS_SECRET_ACCESS_KEY

  # # Uncomment the next lines to recover from the S3 backup. Once the
  # # data has been recovered successfully, the lines can be commented again.
  # clone:
  #   cluster: "test-cluster"  # the same as the name of this cluster!
  #   timestamp: "2199-01-01T00:00:00.000+00:00"  # far away in the future

  # # Uncomment the next lines to create a standby cluster from the S3 backup.
  # # Once the standby cluster has been sycnronized, comment the lines again
  # # to detach the standby cluster from the primary cluster.
  # standby:
  #   s3_wal_path: "s3://swpt/spilo/test-cluster/wal/17"
